# -*- coding: utf-8 -*-
"""LSTM Weather.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lG1-eOc4Zq9a-A9dLofJKDsaaYD_ijJD
"""

import tensorflow as tf
import os
import pandas as pd
import numpy as np
import requests

api_url = 'https://archive-api.open-meteo.com/v1/archive?latitude=43.7001&longitude=-79.4163&start_date=2013-01-01&end_date=2023-07-01&hourly=temperature_2m,relativehumidity_2m,dewpoint_2m,precipitation,weathercode,cloudcover,windspeed_10m,soil_moisture_0_to_7cm'

response = requests.get(api_url)

weather_data = response.json()

hourly_data = weather_data['hourly']

# Create an empty DataFrame to store the flattened data
weather_df = pd.DataFrame()

# Add each feature to the DataFrame as a new column
for feature, values in hourly_data.items():
    weather_df[feature] = values

# Convert time column to datetime object
weather_df["time"] = pd.to_datetime(weather_df["time"])

# Set the "time" column as the index
weather_df.set_index("time", inplace=True)

# Reorder columns so that 'precipitation' is the first column
cols = list(weather_df.columns)
cols.insert(0, cols.pop(cols.index('precipitation')))
weather_df = weather_df.loc[:, cols]

def df_to_X_y(df, window_size=5):
  df_as_np = df.to_numpy()
  X = []
  y = []
  for i in range(len(df_as_np) - window_size):
    row = df_as_np[i:i+window_size]
    X.append(row)
    label = df_as_np[i+window_size, 0]
    y.append(label)
  return np.array(X), np.array(y)

window_size = 5
X, y = df_to_X_y(weather_df)

num_features = weather_df.shape[1]  # Number of features

from sklearn.model_selection import train_test_split

# First split the data into 70% training and 30% temporary
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)

# Then split the 30% temporary set into halves to create the validation and testing set
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import *
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.metrics import RootMeanSquaredError
from tensorflow.keras.optimizers import Adam

model1 = Sequential()
model1.add(InputLayer((window_size, num_features)))  # Modify the input shape to match the number of features
model1.add(LSTM(64))
model1.add(Dense(8, 'relu'))
model1.add(Dense(1, 'linear'))

# Only save the best model (lowest validation loss)
cp = ModelCheckpoint('model1/', save_best_only=True)


model1.compile(loss=MeanSquaredError(),
               optimizer=Adam(learning_rate=0.0001),
               metrics=[RootMeanSquaredError()])

model1.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, callbacks=[cp])

from tensorflow.keras.models import load_model

model1 = load_model('model1/')

train_predictions = model1.predict(X_train).flatten()
train_results = pd.DataFrame(data={'Train Predictions':train_predictions, 'Actuals':y_train})
train_results

import matplotlib.pyplot as plt
plt.plot(train_results['Train Predictions'][50:100])
plt.plot(train_results['Actuals'][50:100])

val_predictions = model1.predict(X_val).flatten()
val_results = pd.DataFrame(data={'Val Predictions':val_predictions, 'Actuals':y_val})
val_results

plt.plot(val_results['Val Predictions'][50:150])
plt.plot(val_results['Actuals'][50:150])

def predict_next_hour():

    # Create an empty DataFrame to store the flattened data
    latest_weather_df = pd.DataFrame()

    # Add each feature to the DataFrame as a new column
    for feature, values in hourly_data.items():
        latest_weather_df[feature] = values[-window_size:] # Taking only the latest 'window_size' entries

    # Reorder columns to match the order used for training
    cols = list(weather_df.columns)
    cols.insert(0, cols.pop(cols.index('precipitation')))
    latest_weather_df = latest_weather_df.loc[:, cols]

    # Convert DataFrame to numpy array and reshape it to match the input shape that the model expects
    latest_data = latest_weather_df.to_numpy().reshape(1, window_size, num_features)

    # Use the trained model to make a prediction
    prediction = model1.predict(latest_data)
    print(f'The predicted precipitation for the next hour is: {prediction[0][0]} mm')


predict_next_hour()

